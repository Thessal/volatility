\documentclass{article}
\usepackage{amsmath}
\begin{document}
\section{Notation}
\begin{itemize}
    \item 1-second last mid price was observed for 1-month 
    \item Daily volatility is being estimated
    \item Sampling period : K (60 * 10) (FIXME:10 minute; why?)
    \item Parameter estimation period : M (60 * 60 * 24 = 86400) (FIXME: 1 day; why?)
    \item Sequence length : n (86400 * 30 = 2592000)
    \item time : $0<t<n$
    \item log-price : $x_t$ 
    \item log-return : $r_t$ 
\end{itemize}

\section{Jump adjust}
Removes jumps and stitch the log-price

\subsection{Truncation}
Truncation with $1\sigma$ was used. $$\tilde r_t = \Psi_\tau(r_t) = \mathrm{sgn}(r_t) \min\left(|r_t|, \tau=\sigma_t\right)$$
where $\sigma^2 = \frac{1}{M}\sum_{i=t}^{t+M}r_i$ .\\
~\\
$\tau = \sigma$ ensures the truncated process ensures sub-Gaussian condentration condition
by Hoeffding's lemma
$$E[\exp(\lambda r_t)] \leq \exp\left(\frac{\lambda^2 \tau^2}{2}\right) = \exp\left(\frac{\lambda^2 \sigma^2}{2}\right) $$

\subsection{Truncation with MLE}
It was assumed that the standard deviation of truncated return goes to the standard deviation of daily return.
\begin{itemize}
    \item Raw return : $r_t$
    \item Truncated return with threshold $\tau$ : $\tilde r_t^\tau$
    \item Standard deviation : $\sigma_t^\tau = \sqrt{\sum_{i=1}^{M}(\tilde r_{t+i}^\tau )^2}$
    \item Daily return : $r_t^\text{daily} = \frac{1}{M} \sum_{i=0}^{M-1}r_{t+i}$
    \item Daily standard deviation : $\sigma_t^\text{daily} = \sqrt{\sum_{i=1}^{M}(r_{t+i}^\text{daily})^2}$
    \item Error : $\epsilon(\tau) = |\sigma_t^\tau - \sigma_t^\text{daily}|$
    \item Loss : $l^\sigma(\epsilon(\tau))$ where loss function $l^\sigma$ is Huber loss with 1$\sigma$ boundary.
    \item Optimal truncation threshold : $\hat\tau = \arg\min_\tau \left(  l^\sigma(\epsilon(\tau)) \right)$
\end{itemize}

\subsection{Benchmark}
Does not remove jump noise for benchmark purpose

\section{Microstructure noise adjust}
Removes high-frequency component

\subsection{Pre-Averaging}
Windowing 
$$r_{PA} = r_t * w $$
was applied to the raw return $r_t$ with window size = K and 
window function $w(s) = \min(s+1, (K-s))$

\subsection{Fractional diffusion}
Models price process as fractional diffusion, and removes drift.\\
Derivative with order < 0.2 is considered as drift, because stationarity is achieved (ADF test with p=0.01) at 0.2-th derivative.
Fractional differentiation is an analytic continuation of discrete differentiation.
$$ \frac{\partial^n x_t}{\partial t^n} = x(t) * w(s) ~~\mathrm{where}~~ w(s)=(_nC_s (-1)^s) $$
$$ \frac{\partial^n x_t}{\partial t^n} = x(t) * w(s) ~~\mathrm{where}~~ w(s)=\left(\frac{\Gamma(n+1)}{\Gamma(s+1)\Gamma(n-s+1)} (-1)^s\right) $$

See : Jiahao Jiang, Bing Miao; A study of anomalous stochastic processes via generalizing fractional calculus. Chaos 1 February 2025; 35 (2): 023156. https://doi.org/10.1063/5.0244009\\

\subsection{Pad\'e transform}
Models jumps as Lorentz peak of oscillator resonance.

\section{Volatility estimation}
Estimate volatility, for given raw log-price and denoised log-price.
\subsection{RV}
Baseline. $\sigma_t = \frac{1}{K}\sum_{i=t}^{t+K} r_i^2$
\subsection{TSRV}
Two-scale realized volatility
$$({\sigma_t^{TRV}})^2 = 
\frac{1}{K}\sum_{i=t}^{t+K} (r_t^{PA})^2 
- \frac{1}{2} \sum_{i=t}^{t+K}r_i^2 \sum_{s=1}^{K-1} \left( w(s) - w(s-1)^2\right)$$

\subsection{PRV}
Pre-averaging realized volatility with noise adjustment
$$({\sigma_t^{PRV}})^2 = \frac{1}{K}\sum_{i=t}^{t+K} (r_t^{PA})^2 - \frac{1}{2} \sum_{i=t}^{t+K}r_i^2 \sum_{s=1}^{K-1} \left( w(s) - w(s-1)^2\right)$$
where $w$ is window function.

\section{Evaluation}
Compare methods based on information measure
\subsection{KLD of Conditional distribution}
Measures the amount of information in time Filtration $\mathcal{F}_t$.
$$\mathrm{KL} ( P | P_0 ) $$
where $P = P(\sigma_t|\sigma_t{-1}) = P(\sigma_{t}|\mathcal{F}_t)P(\sigma_{t-1})$ and $P_0 = P(\sigma_t)P(\sigma_t) = P(\sigma_{t})P(\sigma_{t-1})$.
P is estimated using kernel density estimation.

\subsection{Self-similarity dimension}.
Fractal dimension is used to measure information amount, using box-counting method.

\subsection{Minkowski Measure}
For given fractal dimension, measures persistency.

\end{document}